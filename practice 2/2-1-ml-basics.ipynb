{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd546dc3",
   "metadata": {
    "editable": false,
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart Kernel) and then **run all cells** (in the menubar, select Run$\\rightarrow$Run All Cells). Alternatively, you can use the **validate** button in the assignment list panel.\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\". When you insert your Code you can remove the line `raise NotImplementedError()`. Also put your name, matriculationnumber, and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8936cee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\"\n",
    "MATRICULATIONNUMBER = \"\"\n",
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e5c8a0",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85236ea5-33e0-404f-aa21-01b265906d48",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "22851844135f835a260ea35421925f9e",
     "grade": false,
     "grade_id": "21-intro-text",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "user_expressions": []
   },
   "source": [
    "<img src=\"images/logo_ifn.svg\" alt=\"Drawing\" style=\"width: 256px;\" align=\"right\"/>\n",
    "\n",
    "# Exercise 2.1: Machine Learning Basics\n",
    "\n",
    "After you have learned how to handle the programming language Python, you are ready for some real exercises in machine learning (ML). The main aim of this unit is that you develop a rough intuition for ML model design and selection, method evaluation, and data loading. You will train various different ML models as well as your first small-scale neural network. While the remaining 5 tasks will focus solely on neural networks and deep learning, in this unit you will also learn about cases, where a neural network is maybe not the best choice or where other methods yield good solutions with less method complexity. As previous we first need to import some libraries. Concretely, we import the os, the numpy, the matplotlib, and the sklearn libraries, which all have online-available documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eebcab6a-b4a9-408b-a7b5-9d3ecfca2d0b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "init_cell": true,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7646ea8926c0d75617d6631b2c38cec1",
     "grade": false,
     "grade_id": "21-imports",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "scene__Default Scene": true,
    "scene__Legacy Init": true,
    "tags": [
     "ActiveScene"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import params\n",
    "from ipylab import JupyterFrontEnd\n",
    "PARAM_1, PARAM_2, PARAM_3 = params.gen_params(os.getcwd())\n",
    "PARAM_4 = int(params.gen_params(os.getcwd(), mode='float', num=1)[0] *100000)\n",
    "app = JupyterFrontEnd()\n",
    "app.commands.execute('notebook:render-all-markdown')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed07103-d4e5-4788-b925-bfc767a45acf",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "da63001e52e8d8d2d23ad6c06668d1d0",
     "grade": false,
     "grade_id": "21-a-task",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "user_expressions": [
     {
      "expression": "PARAM_4",
      "result": {
       "data": {
        "text/plain": "13832"
       },
       "metadata": {},
       "status": "ok"
      }
     },
     {
      "expression": "500 + PARAM_1 * 4",
      "result": {
       "data": {
        "text/plain": "572"
       },
       "metadata": {},
       "status": "ok"
      }
     },
     {
      "expression": "3 + PARAM_2 % 5",
      "result": {
       "data": {
        "text/plain": "5"
       },
       "metadata": {},
       "status": "ok"
      }
     },
     {
      "expression": "3 + PARAM_2 % 5",
      "result": {
       "data": {
        "text/plain": "5"
       },
       "metadata": {},
       "status": "ok"
      }
     },
     {
      "expression": "-(0.5 + PARAM_1 % 2 / 4)",
      "result": {
       "data": {
        "text/plain": "-0.5"
       },
       "metadata": {},
       "status": "ok"
      }
     },
     {
      "expression": "0.5 + PARAM_1 % 2 / 4",
      "result": {
       "data": {
        "text/plain": "0.5"
       },
       "metadata": {},
       "status": "ok"
      }
     },
     {
      "expression": "0.5 + PARAM_1 % 2 / 4",
      "result": {
       "data": {
        "text/plain": "0.5"
       },
       "metadata": {},
       "status": "ok"
      }
     },
     {
      "expression": "0.5 + PARAM_1 % 2 / 4",
      "result": {
       "data": {
        "text/plain": "0.5"
       },
       "metadata": {},
       "status": "ok"
      }
     },
     {
      "expression": "(3 + PARAM_2 % 3)/2",
      "result": {
       "data": {
        "text/plain": "2.0"
       },
       "metadata": {},
       "status": "ok"
      }
     },
     {
      "expression": "(3 + PARAM_2 % 3)/2",
      "result": {
       "data": {
        "text/plain": "2.0"
       },
       "metadata": {},
       "status": "ok"
      }
     },
     {
      "expression": "1000 + PARAM_1 * 4",
      "result": {
       "data": {
        "text/plain": "1072"
       },
       "metadata": {},
       "status": "ok"
      }
     },
     {
      "expression": "1000 + PARAM_1 * 4",
      "result": {
       "data": {
        "text/plain": "1072"
       },
       "metadata": {},
       "status": "ok"
      }
     }
    ]
   },
   "source": [
    "<img src=\"images/xor-data-distribution.png\" alt=\"Drawing\" style=\"width: 256px;\" align=\"right\"/>\n",
    "\n",
    "### Task 2.1-A: Classification Data Generation (5P) \n",
    "\n",
    "As a first step, we need to create a toy data distribution. In this exercise we want to use a simple 2D data distribution for the XOR problem, where the decision boundary cannot be linear. While this example is not the most difficult, it is easy to analyse and the results can be easily visualized. An example for the desired data distribution of this task is given on the right hand side of this cell. You can visualize your generated data distribution using the plot function two cells below. To obtain this data distribution implement the following steps in the below function `generate_xor_data`:\n",
    "- Set the random seed to {{PARAM_4}} to ensure reproducibility when executing the function several times\n",
    "- Generate {{500 + PARAM_1 * 4}} uniform randomly distributed x and y coordinates in the range \\[-{{3 + PARAM_2 % 5}} , {{3 + PARAM_2 % 5}}\\]. \n",
    "- Assure that the padding interval \\[{{-(0.5 + PARAM_1 % 2 / 4)}}, {{0.5 + PARAM_1 % 2 / 4}}\\] in both dimensions is free of points (as in th picture on the right) by adding {{0.5 + PARAM_1 % 2 / 4}} to all corrdinates >0 and subtracting {{0.5 + PARAM_1 % 2 / 4}} from all coordinates <=0 after they have been generated.\n",
    "- In practice, labels are often noisy. We want to simulate that by assigning labels -1 and 1 to the data based on modified coordinates. For these modified coordinates we add a random number from the interval \\[-{{(3 + PARAM_2 % 3)/2}} , {{(3 + PARAM_2 % 3)/2}}\\]. Then, assign labels using the XOR criterion based on the modified coordinates. For the XOR problem we assign the label 1 if both coordinates are positive or both coordinates are negative, otherwise we would assign the label -1. We treat 0 as neither positive not negative.\n",
    "- Return the non-noisy coordinates as a numpy array `data` in the shape ({{1000 + PARAM_1 * 4}}, 2) as well as the noisy labels as `labels` in the shape ({{1000 + PARAM_1 * 4}},). Your final distribution should appear similar (not exactly the same!) as in the image shown on the right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd2ba32-1ce3-4567-b4b1-7f551ee1d1d3",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2ef187c2204c9d4364ab8b89d9c21924",
     "grade": false,
     "grade_id": "21-a-answer",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def generate_xor_data():\n",
    "    # YOUR CODE HERE\n",
    "    #1.\n",
    "    np.random.seed(13832)\n",
    "    #2.\n",
    "    x = np.random.uniform(-5,5, 572)\n",
    "    y = np.random.uniform(-5,5,500 + PARAM_1 * 4) \n",
    "    #3.\n",
    "    x[x>0]+=0.5\n",
    "    x[x<0]-=0.5\n",
    "    y[y>0]+=0.5\n",
    "    y[y<0]-=0.5\n",
    "    \n",
    "    modified_x =np.random.uniform(-2.0, 2.0,1)\n",
    "    modified_y =np.random.uniform(-2.0, 2.0,1)\n",
    "    x = np.append(x, modified_x)\n",
    "    y = np.append(y, modified_y)\n",
    "    labels = np.where(np.logical_xor(x>0,y>0),-1,1)\n",
    "    data = np.column_stack((x,y))\n",
    "    \n",
    "    \n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1a859d-e138-4a31-b8ca-794731b831e6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "286969bd22818887032041dfd8ebe206",
     "grade": true,
     "grade_id": "21-a-test",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "data, labels = generate_xor_data()\n",
    "assert type(data) == np.ndarray\n",
    "assert type(labels) == np.ndarray\n",
    "\n",
    "def plot_data(x, y, label):\n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    ax.scatter(x[label == 1], y[label == 1], s=40, facecolors='#00EB2C', edgecolors='white')\n",
    "    ax.scatter(x[label == -1], y[label == -1], s=40, facecolors='#2679B6', edgecolors='white')\n",
    "    plt.show()\n",
    "    \n",
    "plot_data(data[:,0], data[:,1], labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786aea1d-4eac-4689-a908-49fa0d22b831",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "133e08c2c730de9bd4b80c92e918e321",
     "grade": false,
     "grade_id": "21-b-task",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "user_expressions": []
   },
   "source": [
    "### Task 2.1-B: Data Splitting (3P) \n",
    "\n",
    "Machine learning usually involves three sets of data: The training set, where the model is trained on, a validation set, which monitors the model performance during training and gives clues how much the model generalizes to unknown data, and a test set, where the final model is benchmarked. In this task, we want to split the data created in the previous task into these three distinct subsets. For this, retain the order of array dimensions and apply the following:\n",
    "- Use the first 50\\% of elements for the training set (don't apply shuffling) and return them as ``data_train`` and ``labels_train``\n",
    "- Use the following 25\\% of elements for the validation set (don't apply shuffling) and return them as ``data_val`` and ``labels_val``\n",
    "- Use the last 25\\% of elements for the test set (don't apply shuffling) and return them as ``data_test`` and ``labels_test``\n",
    "(Hint: 25\\% = 50\\% \\* 50\\%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce12e79-29c9-4a18-9aae-a13aacad6b89",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d8b748fcd319ef3cf4a608f221aeef4c",
     "grade": false,
     "grade_id": "21-b-answer",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def split_data(data, labels):\n",
    "    # YOUR CODE HERE\n",
    "    num_samples = len(data)\n",
    "    train_end = int(0.5 * num_samples)\n",
    "    val_end = int(0.75 * num_samples)\n",
    "    \n",
    "    data_train,labels_train = data[:train_end],labels[:train_end]\n",
    "    data_val,labels_val = data[train_end:val_end],labels[train_end:val_end]\n",
    "    data_test,labels_test = data[val_end:],labels[val_end:]\n",
    "    \n",
    "    return data_train, data_val, data_test, labels_train, labels_val, labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d269cd1-9d32-4804-bf47-240ae4c1c653",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "84ce043d47795be331e11945772267d1",
     "grade": true,
     "grade_id": "21-b-test",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "data_train, data_val, data_test, labels_train, labels_val, labels_test = split_data(data, labels)\n",
    "assert type(data_train) == np.ndarray\n",
    "assert type(labels_train) == np.ndarray\n",
    "assert type(data_val) == np.ndarray\n",
    "assert type(labels_val) == np.ndarray\n",
    "assert type(data_test) == np.ndarray\n",
    "assert type(labels_test) == np.ndarray\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22247ddd-7cd2-4621-af39-c44cc0caa1bb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5b8d56506a6461c842d50aed65255f3a",
     "grade": false,
     "grade_id": "21-c-task",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "user_expressions": [
     {
      "expression": "PARAM_2",
      "result": {
       "data": {
        "text/plain": "67"
       },
       "metadata": {},
       "status": "ok"
      }
     },
     {
      "expression": "'lbfgs' if PARAM_1 % 2 == 0 else 'liblinear'",
      "result": {
       "data": {
        "text/plain": "'lbfgs'"
       },
       "metadata": {},
       "status": "ok"
      }
     },
     {
      "expression": "'l2' if PARAM_2 % 2 == 0 or PARAM_1 % 2 == 0 else 'l1'",
      "result": {
       "data": {
        "text/plain": "'l2'"
       },
       "metadata": {},
       "status": "ok"
      }
     }
    ]
   },
   "source": [
    "### Task 2.1-C: Linear Classification Models (5P) \n",
    "\n",
    "Now that we have created data, let's try to fit a model to this data distribution. Below you can find the initialization for a simple linear logistic regression model from the sklearn library:\n",
    "- Fit this model to the data (using the standard settings from sklearn) and return the class predictions (maximum class probability) on the validation set as ``result`` and set the parameter ``random_state`` to {{PARAM_2}}. Check out the documentation of sklearn for an example on how to do this. \n",
    "- Try to visualize the results and interpret them. Discuss with fellow students in the course why the model is not able to fit the data distribution.\n",
    "- Try to change the parameters ``solver`` and ``penalty`` of the ``LogisticRegression`` class and see how that affects the results on the validation set. In the end, set the parameters as solver = {{'lbfgs' if PARAM_1 % 2 == 0 else 'liblinear'}} and penalty = {{'l2' if PARAM_2 % 2 == 0 or PARAM_1 % 2 == 0 else 'l1'}}. Discuss why you are not able to improve the results.\n",
    "\n",
    "Note: Whenever there is a task for you to discuss something, you do not need to write this down anywhere explicitly in the notebook. It is merely meant for you and your fellow students to gain a deeper understanding into the topics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e08aed7-53d4-4463-85e1-a4e68cda3fa6",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9e124b520e141e21646b197b11276092",
     "grade": false,
     "grade_id": "21-c-answer",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def linear_cls(d_train, l_train, d_val):\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    clf = LogisticRegression(random_state=67)\n",
    "    # YOUR CODE HERE\n",
    "    clf.fit(d_train,l_train)\n",
    "    result  = clf.predict(d_val)\n",
    "    return result\n",
    "\n",
    "linear_val_result = linear_cls(data_train, labels_train, data_val)\n",
    "\n",
    "# plotting command here\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d37904-a539-489b-8adc-add0f3bc92df",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "062e646eab0eeb9c4a35109ac7f6cf07",
     "grade": true,
     "grade_id": "21-c-test",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "linear_val_result = linear_cls(data_train, labels_train, data_val)\n",
    "assert type(linear_val_result) == np.ndarray\n",
    "assert linear_val_result.shape == labels_val.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80bc580-ecfa-4350-a1b9-3cc3a4d9fd6b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "323dee50483f39110d8dcf8f9e66b017",
     "grade": false,
     "grade_id": "21-d-task",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "user_expressions": []
   },
   "source": [
    "### Task 2.1-D: Classification Evaluation (4P) \n",
    "\n",
    "The first step in debugging a machine learning model is often to visually check, if the result makes sense. This is what we did in the previous section by looking at the 2D plots. Even if we go to more complex tasks, this strategy mostly remains the same as qualitative results often provide more insights than pure metrics. Nevertheless, to also quantify the method's performance, we also need metrics. Implement the following metrics interpreting the class 1 as the positive class:\n",
    "- The accuracy indicating how many overall samples have been classified correctly. Discuss why this can often be a bad measure.\n",
    "- The precision indicating how many predicted samples of class 1 are correctly classified\n",
    "- The recall indicating how many ground truth samples of a class 1 have been classified corrctly\n",
    "- The F1 score taking both precision and recall into account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484b4b35-f72e-497a-b7c9-dc2fba50713b",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4a97bf1fc1145d9d165f01331a40c6d5",
     "grade": false,
     "grade_id": "21-d-answer",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_cls(gt, pred):\n",
    "    # YOUR CODE HERE\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "    acc = accuracy_score(gt,pred)\n",
    "    prec = precision_score(gt,pred)\n",
    "    rec = recall_score(gt,pred)\n",
    "    f1 = f1_score(gt,pred)\n",
    "    return acc, prec, rec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e1aa39-8069-4354-bb7a-bfd7cdd13202",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aa173488f824f60dcfbd84ec04b88b32",
     "grade": true,
     "grade_id": "21-d-test",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "acc, prec, rec, f1 = evaluate_cls(labels_val, linear_val_result)\n",
    "print(acc, prec, rec, f1)\n",
    "assert type(f1) == np.float64\n",
    "assert type(prec) == np.float64\n",
    "assert type(rec) == np.float64\n",
    "assert type(acc) == np.float64\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7faf5c0-8747-4461-a0e6-91158951e85b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "624d521a1bf06b75740e869c99be24cf",
     "grade": false,
     "grade_id": "21-e-task",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "user_expressions": []
   },
   "source": [
    "### Task 2.1-E: Data Preprocessing (4P) \n",
    "\n",
    "Let's try to improve the result from above. We have two angles from which we can approach the problem: From the data perspective and from the model perspective. Starting with the data, we note that a linear model cannot separate the non-linearly separable data. However, the data may be preprocessed such that it becomes separable. Try to implement such a preprocessing and use it to preprocess the data for your function `linear_cls` above. You can verify that your solution is correct by plotting the result and computing the metrics (which should improve significantly). Your achieved F1-score and accuracy should both be higher than 0.75."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dab10e-a416-48f0-838f-0c2e7ca419f7",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d648c56bc831e8fd817db467237ea55a",
     "grade": false,
     "grade_id": "21-e-answer",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def preprocess(d):\n",
    "    # YOUR CODE HERE\n",
    "    d_prep =d * 2\n",
    "    return d_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f156066c-66fe-47b0-8421-37e0661b700e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1dcd0b80d5d36acd0806bba2a42108a0",
     "grade": true,
     "grade_id": "21-e-test",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "prep_val_result = linear_cls(preprocess(data_train), labels_train, preprocess(data_val))\n",
    "assert type(prep_val_result) == np.ndarray\n",
    "assert prep_val_result.shape == labels_val.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d076609d-937e-4c04-be4a-975285ac4c5a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "525dda1439de35cf5e5e5193c60edee6",
     "grade": false,
     "grade_id": "21-f-task",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "user_expressions": [
     {
      "expression": "PARAM_4",
      "result": {
       "data": {
        "text/plain": "13832"
       },
       "metadata": {},
       "status": "ok"
      }
     }
    ]
   },
   "source": [
    "### Task 2.1-F: Non-Linear Classification Models (4P) \n",
    "\n",
    "Apart from preprocessing the data, we can also make use of non-linear models such as Support Vector Machines (SVMs). Fit the SVM model (initialized with `random_state` as {{PARAM_4}}) and return the model predictions on the validation set. Also in this case the performance should be significantly improved both qualitatively and quantitatively. Your achieved F1-score and accuracy should both be higher than 0.75."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945ea4ad-8545-4597-8311-12fd7820a12d",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dfb5c187f496a9ba65aea33bfc602f54",
     "grade": false,
     "grade_id": "21-f-answer",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def non_linear_cls(d_train, l_train, d_val):\n",
    "    from sklearn.svm import SVC\n",
    "    # YOUR CODE HERE\n",
    "    svm = SVC(random_state = 13832)\n",
    "    svm.fit(d_train,l_train)\n",
    "    result = svm.predict(d_val)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c79617-bdfe-4804-9196-1749aa136e6e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "44ec9b9f4d7abdb025752868c1460f69",
     "grade": true,
     "grade_id": "21-f-test",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "nonlinear_val_result = non_linear_cls(data_train, labels_train, data_val)\n",
    "assert type(nonlinear_val_result) == np.ndarray\n",
    "assert nonlinear_val_result.shape == labels_val.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2271ed0a-f9ca-441a-baf0-120d59dc201a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8ff2f21d3fcbeede915c0928f6fe33bd",
     "grade": false,
     "grade_id": "21-g-task",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "user_expressions": [
     {
      "expression": "PARAM_4",
      "result": {
       "data": {
        "text/plain": "13832"
       },
       "metadata": {},
       "status": "ok"
      }
     }
    ]
   },
   "source": [
    "### Task 2.1-G: Unsupervised Clustering (5P)\n",
    "\n",
    "In cases where we do not have many labels, we often still want to implement a classification. In this case, unsupervised methods are of interest. Apply the KMeans algorithm (initialized with `random_state` as {{PARAM_4}}) on the problem and return the predictions on the validation set. (Hint: how many clusters do you need for a meaningful application of the algorithm?). Discuss with your fellow students how you could use the result of the KMeans algorithm to obtain the same result as in the supervised case and the according requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a227f757-d251-4123-9739-e27b43f0b90c",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2ea8b26f167e130a017674e7a653cd9b",
     "grade": false,
     "grade_id": "21-g-answer",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def unsupervised_cls(d_train, d_val):\n",
    "    from sklearn.cluster import KMeans\n",
    "    # YOUR CODE HERE\n",
    "    num_clusters = 2\n",
    "    kmeans = KMeans(n_clusters = num_clusters,random_state = 13832,n_init=10)\n",
    "    kmeans.fit(d_train)\n",
    "    \n",
    "    result = kmeans.predict(d_val)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b74367b-b118-4e1b-a2ad-2993bae11d27",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "90ef83b7ace5f5682f4f7d53f662f49f",
     "grade": true,
     "grade_id": "21-g-test",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "unsupervised_result = unsupervised_cls(data_train, data_val)\n",
    "assert type(unsupervised_result) == np.ndarray\n",
    "assert unsupervised_result.shape == labels_val.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5affb599-d25a-4b28-bd55-796ad1b03a32",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c04a4d523ccecf4a4efb7df781151eb8",
     "grade": false,
     "grade_id": "21-h-task",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "user_expressions": [
     {
      "expression": "PARAM_4 * 2",
      "result": {
       "data": {
        "text/plain": "27664"
       },
       "metadata": {},
       "status": "ok"
      }
     }
    ]
   },
   "source": [
    "### Task 2.1-H: Linear Regression Models (10P) \n",
    "\n",
    "Now we want to apply our knowledge acquired above to a very simple regression problem. Below you can find the data generation code for a data distribution which can be approximated by a linear regression. Implement the following steps:\n",
    "- Generate a data distribution using the given function with a seed of {{PARAM_4 * 2}}\n",
    "- Use the first 50\\% of data for training, the second 25\\% for validation and the last 25\\% for testing and return them as `d_train`, `d_val`, and `d_test` (don't use data shuffling). \n",
    "- Fit a linear regression model on the training set which regresses the y-value from the x-value. Afterwards, return the predictions on the test set (not the validation set) as `result`. The `result` array should have the shape (100,). \n",
    "- Implement an evaluation that computes the mean absolute error and the mean squared error and returns them as `mae` and `mse`. Assume that pred and gt both have the same shape.\n",
    "- Implement a function that executes all of the above functions such that the predictions as well as the MAE and MSE metrics can be returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0f01eb-0823-401b-8602-f5d62657c4cf",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8594667b82f04dafc09728e421253d0f",
     "grade": false,
     "grade_id": "21-h-answer",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def generate_data(seed = 0):\n",
    "    np.random.seed(seed=27664)\n",
    "    x = np.random.uniform(0,10,400)\n",
    "    y = 0.3*x + 2 + np.random.uniform(-0.5, 0.5, 400)\n",
    "    data_reg = np.stack([x,y], axis=1)\n",
    "    return data_reg\n",
    "\n",
    "def split_data(d_reg):\n",
    "    # YOUR CODE HERE\n",
    "    train_end = int(0.5*len(d_reg))\n",
    "    val_end = int(0.75*len(d_reg))\n",
    "    \n",
    "    d_train, d_val, d_test = d_reg[:train_end], d_reg[train_end:val_end], d_reg[val_end:]\n",
    "    return d_train, d_val, d_test\n",
    "\n",
    "def fit_and_predict(d_reg_train, d_reg_test):\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    # YOUR CODE HERE\n",
    "    reg = LinearRegression()\n",
    "    reg.fit(d_reg_train[:,0].reshape(-1,1),d_reg_train[:,1])\n",
    "    result = reg.predict(d_reg_test[:,0].reshape(-1,1))\n",
    "    return result\n",
    "\n",
    "def evaluate_reg(gt, pred):\n",
    "    # YOUR CODE HERE\n",
    "    from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "    mae = mean_absolute_error(gt,pred)\n",
    "    mse = mean_squared_error(gt,pred)\n",
    "    return mae, mse\n",
    "\n",
    "def regression_model():\n",
    "    # don't forget to change the seed ;)\n",
    "    np.random.seed(27664)\n",
    "    data_reg = generate_data()\n",
    "    # YOUR CODE HERE\n",
    "    d_train, d_val, data_reg_test = split_data(data_reg)\n",
    "    reg_result = fit_and_predict(d_train,data_reg_test)\n",
    "    mae,mse = evaluate_reg(data_reg_test[:,1],reg_result)\n",
    "    \n",
    "    return data_reg_test, reg_result, mae, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c96f2f1-046d-47e9-bcb8-f29899cf7716",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "24d01983d368c3431c22468d767deae8",
     "grade": true,
     "grade_id": "21-h-test",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "data_reg_test, reg_result, mae, mse = regression_model()\n",
    "assert data_reg_test.shape == (100,2)\n",
    "assert type(reg_result) == np.ndarray\n",
    "assert len(reg_result) == 100\n",
    "\n",
    "assert type(mae) == np.float64\n",
    "assert type(mse) == np.float64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30d0cdb-d6d2-465f-b7e0-0af979f87936",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "scenes_data": {
   "active_scene": "Default Scene",
   "init_scene": "Default Scene",
   "scenes": [
    "Default Scene"
   ]
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
