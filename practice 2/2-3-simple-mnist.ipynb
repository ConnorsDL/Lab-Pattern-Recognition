{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2a950d0",
   "metadata": {
    "editable": false,
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart Kernel) and then **run all cells** (in the menubar, select Run$\\rightarrow$Run All Cells). Alternatively, you can use the **validate** button in the assignment list panel.\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\". When you insert your Code you can remove the line `raise NotImplementedError()`. Also put your name, matriculationnumber, and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c818f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\"\n",
    "MATRICULATIONNUMBER = \"\"\n",
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0013931",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b979c1-79e9-4193-9ab2-5cedba3b9b3a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "683ed94300c6424992ab461cf02f97f3",
     "grade": false,
     "grade_id": "23-intro-text",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "user_expressions": []
   },
   "source": [
    "<img src=\"images/logo_ifn.svg\" alt=\"Drawing\" style=\"width: 256px;\" align=\"right\"/>\n",
    "\n",
    "# Exercise 2.3: Machine Learning on MNIST\n",
    "\n",
    "After we solved two toy problems on artificial 2D data distributions, we will now approach a first more realistic problem, the digit classification task on MNIST. The dataset is well-known in the machine learning community and a lot of fundamental machine learning research is still carried out on this dataset. To avoid extensive preprocessing, we will use the prepared version of this dataset from the torchvision library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37c99668-bc63-44ee-af75-f36a044ea575",
   "metadata": {
    "deletable": false,
    "editable": false,
    "init_cell": true,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a732b3fe6696d85388ca456be828ca7b",
     "grade": false,
     "grade_id": "23-imports",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "scene__Default Scene": true,
    "scene__Legacy Init": true,
    "tags": [
     "ActiveScene"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn import neural_network\n",
    "from torchvision.datasets import MNIST\n",
    "import params\n",
    "from ipylab import JupyterFrontEnd\n",
    "from threadpoolctl import threadpool_limits\n",
    "\n",
    "PARAM_1, PARAM_2, PARAM_3 = params.gen_params(os.getcwd())\n",
    "PARAM_4 = int(params.gen_params(os.getcwd(), mode='float', num=1)[0] *100000)\n",
    "app = JupyterFrontEnd()\n",
    "app.commands.execute('notebook:render-all-markdown')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55055d3-0d1e-4d6f-ae9d-aa174e214e12",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b704147073343df2c900f992bed706db",
     "grade": false,
     "grade_id": "23-a-task",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "user_expressions": [
     {
      "expression": "PARAM_4",
      "result": {
       "data": {
        "text/plain": "13832"
       },
       "metadata": {},
       "status": "ok"
      }
     },
     {
      "expression": "PARAM_4*2",
      "result": {
       "data": {
        "text/plain": "27664"
       },
       "metadata": {},
       "status": "ok"
      }
     }
    ]
   },
   "source": [
    "### Task 2.3-A: MNIST Data Loading (5P) \n",
    "\n",
    "Before training models on MNIST, we need to normalize the data and reduce the dataset size slightly to enable training in a decent amount of time. The data from torchvision is already normalized and converted to a numpy 1D array. After this, implement the following functions:\n",
    "- Implement the funtion `filter_classes` which filters the data according to the specified digit classes. Assume that the tuple `classes` can have an arbitrary length. \n",
    "- Implement the function `shuffle_data` which shuffles the data. You can use whichever function you like for the shuffling (we will not test the exact implementation).\n",
    "- Implement the function `reduce_set` which only keeps `nb_samples_per_class` samples per class and discards the other samples. Assume that the number of classes in the input is not known in advance.\n",
    "- Implement the function `split_tr_val` which splits the data such that a fraction `proportion_train` of the data is kept in the training set and the rest is put in the validation set.\n",
    "- Implement the function `load_tr_val_splits`, which first filters the data according to the parameter `classes`, then shuffles the data with the random seed {{PARAM_4}}, keeps `nb_samples_per_class` samples per class, shuffles the data again with a random seed {{PARAM_4*2}}, and splits the data in a fixed ratio of 70\\% training data and 30\\% validation data.\n",
    "- Load the data with `X_tr, Y_tr, X_val, Y_val = load_tr_val_splits(classes=(3,8), nb_samples_per_class=1000)` as given below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a16012-7733-495c-89bb-12fca8142d27",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "127bdc14167ade95cd7cab6a8c025b53",
     "grade": false,
     "grade_id": "23-a-functions",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def load_data(sample_id = 8):\n",
    "    mntrain = MNIST('/work/datasets', train=True)\n",
    "    print(\"The label is: \" + str(mntrain.targets.numpy()[sample_id]))\n",
    "    plt.imshow(mntrain.data.numpy()[sample_id])\n",
    "    plt.show()\n",
    "    return mntrain\n",
    "mntrain = load_data(33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ce5bf5-4460-4d16-89e3-d483278b7a60",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e36db7db124255ca8f7eda7112b58e4b",
     "grade": false,
     "grade_id": "23-a-answer",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "X, Y = mntrain.data.flatten(1).float().numpy()/255.0, mntrain.targets.numpy()\n",
    "\n",
    "def filter_classes(X, Y, classes=(3, 8)):\n",
    "    # YOUR CODE HERE\n",
    "    mask = np.isin(Y, classes)\n",
    "    X_N, Y_N = X[mask], Y[mask]\n",
    "    return X_N, Y_N\n",
    "\n",
    "X, Y = filter_classes(X, Y)\n",
    "\n",
    "def shuffle_data(X, Y, seed=0):\n",
    "    np.random.seed(seed)\n",
    "    # YOUR CODE HERE\n",
    "    indices = np.arange(len(X))\n",
    "    np.random.shuffle(indices)\n",
    "    X, Y = X[indices], Y[indices]\n",
    "    return X, Y\n",
    "\n",
    "X, Y = shuffle_data(X, Y)\n",
    "\n",
    "def reduce_set(X, Y, nb_samples_per_class=500):\n",
    "    # YOUR CODE HERE\n",
    "    unique_classes = np.unique(Y)\n",
    "    X_N, Y_N = [], []\n",
    "    for cls in unique_classes:\n",
    "        indices = np.where(Y == cls)[0][:nb_samples_per_class]\n",
    "        X_N.extend(X[indices])\n",
    "        Y_N.extend(Y[indices])\n",
    "    X_N, Y_N = np.array(X_N), np.array(Y_N)\n",
    "    return X_N, Y_N\n",
    "\n",
    "X, Y = reduce_set(X, Y)\n",
    "\n",
    "def split_tr_val(X, Y, proportion_train=0.7):\n",
    "    # YOUR CODE HERE\n",
    "    num_samples = len(X)\n",
    "    num_train = int(num_samples * proportion_train)\n",
    "    X_tr, Y_tr = X[:num_train], Y[:num_train]\n",
    "    X_val, Y_val = X[num_train:], Y[num_train:]\n",
    "    return X_tr, Y_tr, X_val, Y_val\n",
    "\n",
    "X_tr, Y_tr, X_val, Y_val = split_tr_val(X, Y)\n",
    "\n",
    "def load_tr_val_splits(classes, nb_samples_per_class):\n",
    "    mntrain = MNIST('/work/datasets', train=True)\n",
    "    X, Y = mntrain.data.flatten(1).float().numpy()/255.0, mntrain.targets.numpy()\n",
    "    # YOUR CODE HERE\n",
    "    X, Y = filter_classes(X, Y, classes)\n",
    "    X, Y = shuffle_data(X, Y, seed=13832)\n",
    "    X, Y = reduce_set(X, Y, nb_samples_per_class)\n",
    "    X_tr, Y_tr, X_val, Y_val = split_tr_val(X, Y)\n",
    "    return X_tr, Y_tr, X_val, Y_val\n",
    "    \n",
    "X_tr, Y_tr, X_val, Y_val = load_tr_val_splits(classes=(3,8), nb_samples_per_class=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fc94d5-7dd5-435f-b7bb-5b5067b7c59e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "50c73b702c2c65df5fd8e22d47f9cc38",
     "grade": true,
     "grade_id": "23-a-test",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(X_tr) == np.ndarray\n",
    "assert type(Y_tr) == np.ndarray\n",
    "assert type(X_val) == np.ndarray\n",
    "assert type(Y_val) == np.ndarray\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b8b52b-8fc7-481e-abe8-6ccb351180a6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e752aa6c14b7a638fbf6034c8c66f428",
     "grade": false,
     "grade_id": "23-b-task",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "user_expressions": [
     {
      "expression": "PARAM_4",
      "result": {
       "data": {
        "text/plain": "13832"
       },
       "metadata": {},
       "status": "ok"
      }
     }
    ]
   },
   "source": [
    "### Task 2.3-B: Support Vector Machines (5P) \n",
    "\n",
    "For comparison with a deep neural network, we want to write a function `train_svm` that takes the training data as input and returns a trained model:\n",
    "- Implement the corresponding function using the sklearn library. Make sure to initialize the random_state variable with {{PARAM_4}} to ensure reproducibility of your trainings.\n",
    "- Train a model `clf_svm1` with the default parameters given in the function definition. What do you observe regarding the training and validation accuracy? \n",
    "- Train a second model `clf_svm2` with which you improve the performance on the validation set (no specific performance improvement is demanded)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fed3de-26ca-4de9-a963-05549aaecc46",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b7a1cebadb743c8d69d473b6061babc3",
     "grade": false,
     "grade_id": "23-b-answer",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def train_svm(X_tr, Y_tr, \n",
    "              penalty = 1, \n",
    "              kernel_function = 'rbf',\n",
    "              poly_degree = 1,\n",
    "              gamma = 10,\n",
    "              zero_coeff = 0.0,\n",
    "              stopping_criterion = 1e-3,\n",
    "              max_iterations = -1):\n",
    "    # YOUR CODE HERE\n",
    "    clf = svm.SVC(C=penalty, kernel=kernel_function, degree=poly_degree, gamma=gamma, coef0=zero_coeff,\n",
    "                  tol=stopping_criterion, max_iter=max_iterations, random_state=13832)\n",
    "    clf.fit(X_tr, Y_tr)\n",
    "    return clf\n",
    "\n",
    "with threadpool_limits(limits=1, user_api='blas'):\n",
    "    # YOUR CODE HERE\n",
    "    clf_svm1 = train_svm(X_tr, Y_tr)\n",
    "\n",
    "    clf_svm2 = train_svm(X_tr, Y_tr, gamma=0.1, C=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36083e47-a5bf-445e-a536-9710a7e9d020",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "39f2280e389799aea714c39a327abab8",
     "grade": true,
     "grade_id": "23-b-test",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(clf_svm1) == svm._classes.SVC\n",
    "assert type(clf_svm2) == svm._classes.SVC\n",
    "training_accuracy1 = clf_svm1.score(X_tr, Y_tr)\n",
    "validation_accuracy1 = clf_svm1.score(X_val, Y_val)\n",
    "training_accuracy2 = clf_svm2.score(X_tr, Y_tr)\n",
    "validation_accuracy2 = clf_svm2.score(X_val, Y_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a4c84d-88af-424b-b086-b050c53dbe2b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3a64922bff8f91c424fe47212999c9d3",
     "grade": false,
     "grade_id": "23-c-task",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "user_expressions": [
     {
      "expression": "PARAM_4",
      "result": {
       "data": {
        "text/plain": "13832"
       },
       "metadata": {},
       "status": "ok"
      }
     }
    ]
   },
   "source": [
    "### Task 2.3-C: Multi-Layer Neural Networks (5P) \n",
    "\n",
    "In the subsequent task the aim is to implement a function `train_nnet` that takes the training data as input, trains a neural network and returns the trained model. Implement the following:\n",
    "- Implement the corresponding function using the sklearn library. Make sure to initialize the random_state variable with {{PARAM_4}} to ensure reproducibility of your trainings.\n",
    "- Train a model `clf_nnet1` with the default parameters given in the function definition. What do you observe regarding the training and validation accuracy? \n",
    "- Train a second model `clf_nnet2` with which you improve the performance on the validation set. How do different parameters affect the result? What do you observe when optimizing hyperparameters and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a015dfe4-81eb-4891-bd02-77b6527977d1",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "43805d885bbe94159e3b7aea40e9ad53",
     "grade": false,
     "grade_id": "23-c-answer",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def train_nnet(X_tr, Y_tr,\n",
    "               hidden_layer_sizes = (100, 100),\n",
    "               activation = \"relu\", \n",
    "               solver = \"sgd\",\n",
    "               alpha = 0.0001,\n",
    "               batch_size = 200, \n",
    "               learning_rate = \"constant\",\n",
    "               learning_rate_init = 0.001,\n",
    "               max_iter = 50,\n",
    "               shuffle = True,\n",
    "               momentum = 0.9,\n",
    "               nesterovs_momentum = True):\n",
    "    # YOUR CODE HERE\n",
    "    clf = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes,\n",
    "                        activation=activation,\n",
    "                        solver=solver,\n",
    "                        alpha=alpha,\n",
    "                        batch_size=batch_size,\n",
    "                        learning_rate=learning_rate,\n",
    "                        learning_rate_init=learning_rate_init,\n",
    "                        max_iter=max_iter,\n",
    "                        shuffle=shuffle,\n",
    "                        momentum=momentum,\n",
    "                        nesterovs_momentum=nesterovs_momentum,\n",
    "                        random_state=13832)\n",
    "    clf.fit(X_tr, Y_tr)\n",
    "    return clf\n",
    "\n",
    "with threadpool_limits(limits=1, user_api='blas'):\n",
    "    # YOUR CODE HERE\n",
    "    clf_nnet1 = train_nnet(X_tr, Y_tr)\n",
    "    clf_nnet2 = train_nnet(X_tr, Y_tr, hidden_layer_sizes=(50, 50), learning_rate_init=0.01, max_iter=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da14389-ffaf-4af9-adb1-6ac57daeb82d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "441de0ed77c3fc8bac4dd91c1afb7749",
     "grade": true,
     "grade_id": "23-c-test",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(clf_nnet1) == neural_network._multilayer_perceptron.MLPClassifier\n",
    "assert type(clf_nnet2) == neural_network._multilayer_perceptron.MLPClassifier\n",
    "training_accuracy1 = clf_nnet1.score(X_tr, Y_tr)\n",
    "validation_accuracy1 = clf_nnet1.score(X_val, Y_val)\n",
    "training_accuracy2 = clf_nnet2.score(X_tr, Y_tr)\n",
    "validation_accuracy2 = clf_nnet2.score(X_val, Y_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d47bc5a-ac13-4eb7-8ed2-d9303dfb0a48",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "22107355ebc44db8ed979b9d2264a825",
     "grade": false,
     "grade_id": "23-d-task",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "user_expressions": []
   },
   "source": [
    "### Task 2.3-D: Evaluation of the Trained Models (5P) \n",
    "\n",
    "When training support vector machines and neural networks, you have probably noticed that both achieve near 100\\% accuracy on the training set and a strong performance on the validation set. Still, we optimized hyperparameters for the validation set and it is not yet clear, how the models perform on completely unknown data. For this purpose, we will now employ our test set:\n",
    "- Implement the below function to load all (official!) test samples of MNIST. Have a look at the `MNIST` class to determine how the test samples can be loaded. Filter the test set such that it only contains the digit classes specified by `classes`. \n",
    "- Load the test data into variable `X_test` and `Y_test`. Evaluate your models on the test set. Discuss which one performs better and why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37767d8-4b8b-4f13-93f5-3f7d8cfdaf14",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c395258048cd0ebc93194f98cc5ee0d9",
     "grade": false,
     "grade_id": "23-d-answer",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def load_test_splits(classes):\n",
    "    # YOUR CODE HERE\n",
    "    mnist_test = MNIST('/work/datasets', train=False, download=True)\n",
    "    X_test, Y_test = mnist_test.data.flatten(1).float().numpy()/255.0, mnist_test.targets.numpy()\n",
    "    X_test, Y_test = filter_classes(X_test, Y_test, classes)\n",
    "    return X, Y\n",
    "\n",
    "with threadpool_limits(limits=1, user_api='blas'):\n",
    "    # YOUR CODE HERE\n",
    "    X_test, Y_test = load_test_splits(classes=(3,8))\n",
    "    \n",
    "test_accuracy_svm1 = clf_svm1.score(X_test, Y_test)\n",
    "test_accuracy_svm2 = clf_svm2.score(X_test, Y_test)\n",
    "\n",
    "test_accuracy_nnet1 = clf_nnet1.score(X_test, Y_test)\n",
    "test_accuracy_nnet2 = clf_nnet2.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c46681-0fd1-4cd0-95b5-3bf4c6707fb2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b26dff7e7718fff241722ff09a4f0258",
     "grade": true,
     "grade_id": "23-d-test",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(X_test) == np.ndarray\n",
    "assert type(Y_test) == np.ndarray\n",
    "assert type(clf_svm1) == svm._classes.SVC\n",
    "assert type(clf_svm2) == svm._classes.SVC\n",
    "assert type(clf_nnet1) == neural_network._multilayer_perceptron.MLPClassifier\n",
    "assert type(clf_nnet2) == neural_network._multilayer_perceptron.MLPClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dacab7e-0c9a-4219-b625-088d0d7b0791",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d347bb48c11de50fdd47866108c87825",
     "grade": false,
     "grade_id": "23-e-task",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "user_expressions": []
   },
   "source": [
    "### Task 2.3-E: Classification of Different Digits (5P) \n",
    "\n",
    "While we previously only considered the digit classes 3 and 8, we now want to see how our models perform for other digit classes. For this purpose complete the function `eval_other_digits` below:\n",
    "- Load training data with the digit classes specified by `classes` using your previously implemented `load_tr_val_splits` with `nb_samples_per_class=1000`. Remember that this function needs to be deterministic.\n",
    "- train an SVM and a neural network on this data using `train_svm` and `train_nnet` functions using the default parameters. Calculate the accuracies on the test set for both models and return them as `test_svm_acc` and `test_nnet_acc`.\n",
    "- Try out how the models perform for different class combinations and also for more than 2 classes and discuss the result with your fellow students. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6dddd7-2a21-489e-aa82-f55a9faa7fcc",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fa0bd2d8fee14ffa35a4eeab09ffe7e5",
     "grade": false,
     "grade_id": "23-e-answer",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def eval_other_digits(classes):\n",
    "    # YOUR CODE HERE\n",
    "    X_tr, Y_tr, _, _ = load_tr_val_splits(classes, nb_samples_per_class=1000)\n",
    "    \n",
    "    clf_svm = train_svm(X_tr, Y_tr)\n",
    "    clf_nnet = train_nnet(X_tr, Y_tr)\n",
    "    \n",
    "    X_test, Y_test = load_test_splits(classes)\n",
    "    \n",
    "    test_svm_acc = clf_svm.score(X_test, Y_test)\n",
    "    test_nnet_acc = clf_nnet.score(X_test, Y_test)\n",
    "\n",
    "    return test_svm_acc, test_nnet_acc\n",
    "\n",
    "with threadpool_limits(limits=1, user_api='blas'):\n",
    "    test_svm_acc, test_nnet_acc = eval_other_digits((1,7))\n",
    "    print('Result svm-Testing - Accuracy on test data = ' + '{0:g}%'.format(test_svm_acc * 100) + \"\\n\")\n",
    "    print('Result nnet-Testing - Accuracy on test data = ' + '{0:g}%'.format(test_nnet_acc * 100) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9240f90-8405-4e84-a576-f0051fc49ed0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "957ca7e6038525f0fe5acd1986e78f2f",
     "grade": true,
     "grade_id": "23-e-test",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert test_svm_acc >= 0 and test_svm_acc <= 1\n",
    "assert test_nnet_acc >= 0 and test_svm_acc <= 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924bc5fe-f45f-4370-8279-2d71360cf0d1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e9bb8a9fe191faef603d95cb8b01e5ae",
     "grade": false,
     "grade_id": "23-f-task",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "user_expressions": []
   },
   "source": [
    "### Task 2.3-F: Differing Data Amounts (5P) \n",
    "\n",
    "Finally, we want to gain insights into the performances of both neural networks and SVMs on different data amounts. For this purpose complete the function `eval_data_amount` given below:\n",
    "- Load training data with `classes=(3,8)` using your previously implemented `load_tr_val_splits` with `nb_samples_per_class` as specified by `nb_samples`. Remember that this function needs to be deterministic.\n",
    "- train an SVM and a neural network on this data using `train_svm` and `train_nnet` functions using the default parameters. Calculate the accuracies on the test set for both models and return them as `test_svm_acc` and `test_nnet_acc`.\n",
    "- Try out how the models perform for different amounts of data and discuss the result with your fellow students. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66683812-12df-4304-8d70-6a2532bc1bb9",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d75e53cb2423c5567d1e49344935c277",
     "grade": false,
     "grade_id": "23-f-answer",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def eval_data_amount(nb_samples):\n",
    "    # YOUR CODE HERE\n",
    "    X_tr, Y_tr, _, _ = load_tr_val_splits(classes=(3, 8), nb_samples_per_class=nb_samples)\n",
    "    \n",
    "    clf_svm = train_svm(X_tr, Y_tr)\n",
    "    clf_nnet = train_nnet(X_tr, Y_tr)\n",
    "    \n",
    "    X_test, Y_test = load_test_splits(classes=(3, 8))\n",
    "    test_svm_acc = clf_svm.score(X_test, Y_test)\n",
    "    test_nnet_acc = clf_nnet.score(X_test, Y_test)\n",
    "    \n",
    "    return test_svm_acc, test_nnet_acc\n",
    "\n",
    "with threadpool_limits(limits=1, user_api='blas'):\n",
    "    test_svm_acc, test_nnet_acc = eval_data_amount(1000)\n",
    "    print('Result svm-Testing - Accuracy on test data = ' + '{0:g}%'.format(test_svm_acc * 100) + \"\\n\")\n",
    "    print('Result nnet-Testing - Accuracy on test data = ' + '{0:g}%'.format(test_nnet_acc * 100) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d28070-9a4c-47ac-8da2-3c6b02dc5de3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "48101b2bb2e32033189b54dd93971ca0",
     "grade": true,
     "grade_id": "23-f-test",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert test_svm_acc >= 0 and test_svm_acc <= 1\n",
    "assert test_nnet_acc >= 0 and test_svm_acc <= 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c445b6a8-d165-4c58-a2f3-1fdf9c3f7b04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "scenes_data": {
   "active_scene": "Default Scene",
   "init_scene": "Default Scene",
   "scenes": [
    "Default Scene"
   ]
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
